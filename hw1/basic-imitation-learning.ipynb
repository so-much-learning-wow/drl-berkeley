{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import keras\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import load_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(envname, policy, num_rollouts=20, render=False, max_timesteps=None, debug=False):\n",
    "    tf.global_variables_initializer()\n",
    "    \n",
    "    env = gym.make(envname)\n",
    "    max_steps = max_timesteps or env.spec.timestep_limit\n",
    "\n",
    "    returns = []\n",
    "    observations = []\n",
    "    actions = []\n",
    "\n",
    "    for i in range(num_rollouts):\n",
    "        if debug: print('iter', i)\n",
    "\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        totalr = 0.\n",
    "        steps = 0\n",
    "\n",
    "        while not done:\n",
    "            action = policy(obs[None,:])\n",
    "            observations.append(obs)\n",
    "            actions.append(action.flatten())\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            totalr += r\n",
    "            steps += 1\n",
    "\n",
    "            if render: env.render()\n",
    "            if debug and steps % 100 == 0: print(\"%i/%i\"%(steps, max_steps))\n",
    "            if steps >= max_steps: break\n",
    "\n",
    "        returns.append(totalr)\n",
    "\n",
    "    # print('returns', returns)\n",
    "    print('mean return', np.mean(returns))\n",
    "    print('std of return', np.std(returns))\n",
    "\n",
    "    return np.array(observations), np.array(actions)\n",
    "    \n",
    "def run_expert(envname, **args):\n",
    "    policy = load_policy.load_policy('./experts/{}.pkl'.format(envname))\n",
    "    \n",
    "    return run(envname, policy, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "\n",
    "def create_model(num_inputs, num_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(num_inputs,), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_outputs))\n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_imitation_learning(envname, num_simulation_rollouts=50, plot_loss=False):\n",
    "    print('Running expert simulation')\n",
    "    observations, actions = run_expert(envname, num_rollouts=num_simulation_rollouts)\n",
    "    \n",
    "    print('Building model')\n",
    "    model = create_model(observations.shape[1], actions.shape[1])\n",
    "    history = model.fit(observations, actions, batch_size=128, epochs=10, verbose=0)\n",
    "    \n",
    "    print('Running the policy')\n",
    "    run(envname, model.predict, render=True, num_rollouts=10)\n",
    "    \n",
    "    if plot_loss: plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running expert simulation\n",
      "obs (1, 11) (1, 11)\n",
      "mean return 3777.98512749\n",
      "std of return 3.72076657895\n",
      "Building model\n",
      "Running the policy\n",
      "mean return 1346.4365135\n",
      "std of return 503.577265202\n"
     ]
    }
   ],
   "source": [
    "simple_imitation_learning('Hopper-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running expert simulation\n",
      "obs (1, 376) (1, 376)\n",
      "mean return 10399.9780269\n",
      "std of return 55.0311672545\n",
      "Building model\n",
      "Running the policy\n",
      "mean return 935.561437185\n",
      "std of return 725.377516977\n"
     ]
    }
   ],
   "source": [
    "simple_imitation_learning('Humanoid-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dagger(envname, num_iter=10):\n",
    "    print('Running expert simulation')\n",
    "    observations, actions = run_expert(envname, num_rollouts=20)\n",
    "    expert_policy = load_policy.load_policy('./experts/{}.pkl'.format(envname))\n",
    "    \n",
    "    for i in range(0, num_iter):\n",
    "        print('Iteration #', i+1)\n",
    "        # Building the model\n",
    "        model = create_model(observations.shape[1], actions.shape[1])\n",
    "        model.fit(observations, actions, batch_size=128, epochs=num_iter-i, verbose=0)\n",
    "        \n",
    "        # Obtaining new dataset\n",
    "        new_observations, _ = run(envname, model.predict, num_rollouts=50)\n",
    "        \n",
    "        # Getting right labels for the dataset\n",
    "        new_actions = np.array([expert_policy(obs[None, :]).flatten() for obs in new_observations])\n",
    "        \n",
    "        observations = np.concatenate((observations, new_observations))\n",
    "        actions = np.concatenate((actions, new_actions))\n",
    "\n",
    "        \n",
    "    # Finally, let's test our model\n",
    "    model = create_model(observations.shape[1], actions.shape[1])\n",
    "    model.fit(observations, actions, batch_size=128, epochs=10, validation_split=0.2)\n",
    "    run(envname, model.predict, render=True, num_rollouts=30)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running expert simulation\n",
      "mean return 10386.7186736\n",
      "std of return 109.253803277\n",
      "Iteration # 1\n",
      "mean return 454.091469673\n",
      "std of return 97.281529556\n",
      "Iteration # 2\n",
      "mean return 632.852397323\n",
      "std of return 362.913139849\n",
      "Iteration # 3\n",
      "mean return 575.401110447\n",
      "std of return 243.882086636\n",
      "Iteration # 4\n",
      "mean return 1807.5480905\n",
      "std of return 1029.39536148\n",
      "Iteration # 5\n",
      "mean return 1299.58968908\n",
      "std of return 580.708028161\n",
      "Iteration # 6\n",
      "mean return 1295.13438941\n",
      "std of return 595.231154411\n",
      "Iteration # 7\n",
      "mean return 1779.62857762\n",
      "std of return 719.328774714\n",
      "Iteration # 8\n",
      "mean return 1847.4165782\n",
      "std of return 1436.05799611\n",
      "Iteration # 9\n",
      "mean return 1132.35650505\n",
      "std of return 591.357102148\n",
      "Iteration # 10\n",
      "mean return 661.784774391\n",
      "std of return 207.905808332\n",
      "Train on 78244 samples, validate on 19561 samples\n",
      "Epoch 1/10\n",
      "78244/78244 [==============================] - 8s - loss: 0.5076 - val_loss: 0.6090\n",
      "Epoch 2/10\n",
      "78244/78244 [==============================] - 6s - loss: 0.2945 - val_loss: 0.4613\n",
      "Epoch 3/10\n",
      "78244/78244 [==============================] - 6s - loss: 0.2183 - val_loss: 0.3296\n",
      "Epoch 4/10\n",
      "78244/78244 [==============================] - 7s - loss: 0.1718 - val_loss: 0.2486\n",
      "Epoch 5/10\n",
      "78244/78244 [==============================] - 6s - loss: 0.1458 - val_loss: 0.2310\n",
      "Epoch 6/10\n",
      "78244/78244 [==============================] - 6s - loss: 0.1288 - val_loss: 0.2090\n",
      "Epoch 7/10\n",
      "78244/78244 [==============================] - 6s - loss: 0.1196 - val_loss: 0.1931\n",
      "Epoch 8/10\n",
      "78244/78244 [==============================] - 6s - loss: 0.1108 - val_loss: 0.1841\n",
      "Epoch 9/10\n",
      "78244/78244 [==============================] - 6s - loss: 0.1052 - val_loss: 0.1743\n",
      "Epoch 10/10\n",
      "78244/78244 [==============================] - 7s - loss: 0.1004 - val_loss: 0.1767\n",
      "mean return 9390.28353699\n",
      "std of return 2148.16993137\n"
     ]
    }
   ],
   "source": [
    "model = dagger('Humanoid-v1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
